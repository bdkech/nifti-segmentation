# Example configuration for NIFTI 2D slice-based segmentation
# This shows how to configure all aspects of the training pipeline

data:
  data_dir: "./data/volumes"
  annotation_dir: "./data/annotations" 
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1
  
  # Slice processing parameters
  slice_axis: 2                        # Extract slices along sagittal axis (0=axial, 1=coronal, 2=sagittal)
  batch_size: 8                        # Number of slices per batch from same volume
  img_size: [224, 224]                 # Target 2D slice size [H, W]
  
  # Target processing parameters (for 3D volumes before slicing)
  target_spacing: [1.0, 1.0, 1.0]     # 1mm isotropic spacing
  target_size: [224, 224, 64]         # Standard volume size before slicing [H, W, D]
  
  # Hounsfield Unit normalization settings
  use_adaptive_hu_normalization: true  # Recommended for robustness across different scanners
  adaptive_hu_lower_percentile: 0.5    # Lower percentile for windowing
  adaptive_hu_upper_percentile: 99.5   # Upper percentile for windowing
  
  # Alternative: Fixed HU windowing (set use_adaptive_hu_normalization: false)
  # hu_window_preset: "soft_tissue"    # Use predefined window ("soft_tissue", "bone", "lung")
  # hu_min: -160.0                     # Or custom HU range
  # hu_max: 240.0

# Compute and hardware configuration
compute:
  devices: "auto"                      # GPU devices: "auto", "cpu", int (e.g. 1), or list [0, 1, 2]
  accelerator: "gpu"                   # "gpu", "cpu", or "mps" (for Apple Silicon)
  strategy: "ddp"                      # Multi-GPU strategy: "ddp", "fsdp", or "auto"
  precision: "16-mixed"                # Training precision: "32", "16-mixed", "bf16-mixed"
  num_workers: 4                       # Number of data loader workers
  
model:
  img_size: [224, 224]                 # 2D slice size [H, W]
  in_channels: 1
  out_channels: 1
  features: [32, 32, 64, 128, 256, 32] # UNet feature channels for each level
  activation: "PRELU"                  # Activation function
  spatial_dims: 2                      # Fixed to 2D for slice processing
  slice_axis: 2                        # Must match data.slice_axis
  
training:
  epochs: 100                          # Number of training epochs
  batch_size: 8                        # Slices per batch from same volume (must match data.batch_size)
  learning_rate: 1e-4                  # Initial learning rate
  optimizer: "AdamW"                   # Optimizer: "Adam", "AdamW", "SGD"
  loss_function: "dicece"              # Loss function: "dice", "dicece", "focal"
  loss_kwargs: {}                      # Additional loss function parameters
  scheduler: null                      # LR scheduler: "StepLR", "CosineAnnealingLR", "ReduceLROnPlateau"
  scheduler_kwargs: {}                 # Additional scheduler parameters (e.g., step_size, gamma)
  patience: 15                         # Early stopping patience (epochs without improvement)
  min_delta: 1e-6                      # Minimum change considered as improvement
  
wandb:
  enabled: true                        # Enable Weights & Biases logging
  project: "nifti-segmentation"        # W&B project name
  tags: ["unet2d", "slice-based", "hu-normalization"]  # Experiment tags
  name: null                           # Optional experiment name (auto-generated if null)
  notes: null                          # Optional experiment description
  
# Output directory for models, logs, and results
output_dir: "./outputs"