# NiftiLearn - Medical Image Segmentation Pipeline

A production-ready pipeline for medical image segmentation using slice-based 2D UNet architecture with PyTorch Lightning, designed for high-performance workflows with Docker-like CLI experience.

## ğŸ¯ Key Features

- âœ… **Slice-Based Processing**: Efficient 2D UNet on volume slices (one volume per batch)
- âœ… **MONAI Integration**: Built-in loss functions and metrics optimized for medical imaging
- âœ… **PyTorch Lightning**: Professional training with multi-GPU support, checkpointing, early stopping
- âœ… **Hounsfield Unit Processing**: Adaptive and preset-based HU normalization
- âœ… **Volume Reconstruction**: Automatic 2D-to-3D reassembly with metadata preservation
- âœ… **CLI Interface**: Docker-style commands with comprehensive configuration support
- âœ… **Production Ready**: Complete error handling, logging, and type safety

## ğŸ“ Project Structure

```
niftilearn/
â”œâ”€â”€ cli/                        # Command Line Interface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                 # Click-based CLI with train/predict commands
â”œâ”€â”€ config/                     # Configuration Management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loader.py               # YAML configuration loading
â”‚   â””â”€â”€ models.py               # Pydantic configuration models
â”œâ”€â”€ core/                       # Core Utilities
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logging.py              # Loguru logging setup
â”‚   â””â”€â”€ metadata.py             # NIFTI metadata extraction
â”œâ”€â”€ data/                       # Data Pipeline
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ datamodule.py           # Lightning DataModule
â”‚   â”œâ”€â”€ datasets.py             # Volume-based PyTorch datasets
â”‚   â”œâ”€â”€ loaders.py              # NIFTI discovery and loading
â”‚   â””â”€â”€ transforms.py           # Slice extraction and HU processing
â”œâ”€â”€ models/                     # Model Architecture
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ unet.py                 # UNet2D Lightning module with training
â”œâ”€â”€ training/                   # Training Components
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ losses.py               # MONAI loss functions (Dice, Focal, DiceCE)
â”‚   â””â”€â”€ metrics.py              # MONAI segmentation metrics
â””â”€â”€ utils/                      # Utilities
    â”œâ”€â”€ __init__.py
    â””â”€â”€ reconstruction.py       # 2D-to-3D volume reconstruction
```

## ğŸš€ Usage

### CLI Commands
```bash
# Train model with configuration file
niftilearn --config example_config.yaml train

# Train with parameter overrides
niftilearn --config example_config.yaml train --epochs 50 --batch-size 4 --learning-rate 5e-5

# Multi-GPU training with torchrun
torchrun --nproc_per_node=2 -m niftilearn.cli.main --config example_config.yaml train

# Generate predictions on new volumes
niftilearn predict --model checkpoints/best.ckpt --input volume.nii.gz --output segmentation.nii.gz

# Prediction with preprocessing config
niftilearn --config example_config.yaml predict --model checkpoints/best.ckpt --input volume.nii.gz --output segmentation.nii.gz
```

### Python API
```python
# Core imports
from niftilearn.config.loader import load_config
from niftilearn.data.datamodule import NiftiDataModule  
from niftilearn.models.unet import UNet2D
from niftilearn.utils.reconstruction import reconstruct_volume_from_predictions

# Load configuration and create components
config = load_config("example_config.yaml")
model = UNet2D(config.model)
datamodule = NiftiDataModule(config.data)

# Training with Lightning
import pytorch_lightning as pl
trainer = pl.Trainer(max_epochs=config.training.epochs)
trainer.fit(model, datamodule)
```

## ğŸ¥ Medical Image Processing

The pipeline includes specialized processing for medical NIFTI volumes:

### Hounsfield Unit Normalization
- **Adaptive HU Normalization**: Automatic percentile-based windowing for robust preprocessing
- **Fixed HU Windows**: Support for clinical presets (soft tissue, bone, lung)
- **Volume-to-Slice Processing**: Extract 2D slices from 3D volumes along configurable axes

### Slice-Based Architecture
- **One Volume Per Batch**: Process entire volumes as batches of 2D slices
- **Configurable Slice Axis**: Extract slices along axial (0), coronal (1), or sagittal (2) planes
- **Automatic Reconstruction**: Reassemble 2D predictions into 3D volumes with preserved metadata

```yaml
# Configuration example
data:
  slice_axis: 2                        # Sagittal slices
  use_adaptive_hu_normalization: true  # Adaptive HU windowing
  adaptive_hu_lower_percentile: 0.5    # Lower percentile for windowing
  adaptive_hu_upper_percentile: 99.5   # Upper percentile for windowing
  target_spacing: [1.0, 1.0, 1.0]     # Resample to 1mm isotropic
  img_size: [224, 224]                 # 2D slice size
```

## ğŸ”§ Installation

```bash
# Install dependencies with uv (recommended)
uv add monai torch lightning click loguru nibabel wandb numpy scipy pydantic pyyaml rich

# Install in development mode
uv pip install -e .

# Or with pip
pip install -e .
```

## ğŸ“ Configuration

Use YAML configuration files for reproducible experiments. See `example_config.yaml` for complete example:

```yaml
data:
  data_dir: "./data/volumes"
  annotation_dir: "./data/annotations"
  train_split: 0.7
  val_split: 0.2
  test_split: 0.1
  slice_axis: 2                        # Extract sagittal slices
  batch_size: 8                        # Slices per batch from same volume
  img_size: [224, 224]                 # Target 2D slice size
  use_adaptive_hu_normalization: true  # Adaptive HU windowing

model:
  img_size: [224, 224]                 # Must match data.img_size
  in_channels: 1
  out_channels: 1  
  features: [32, 32, 64, 128, 256, 32] # UNet feature channels
  activation: "PRELU"

training:
  epochs: 100
  batch_size: 8                        # Must match data.batch_size
  learning_rate: 1e-4
  optimizer: "AdamW"
  loss_function: "dicece"              # MONAI loss functions
  patience: 15                         # Early stopping patience

compute:
  devices: "auto"                      # GPU devices to use
  accelerator: "auto"                  # gpu/cpu/mps
  precision: "16-mixed"                # Mixed precision training

wandb:
  enabled: false                       # Optional W&B logging
  project: "nifti-segmentation"

output_dir: "./outputs"
```

## ğŸ“Š Training & Metrics

The pipeline automatically tracks comprehensive metrics during training:

- **Loss Functions**: Dice Loss, Focal Loss, Combined Dice+CrossEntropy (MONAI implementations)
- **Metrics**: Dice coefficient, IoU (Intersection over Union), pixel accuracy
- **Checkpointing**: Automatic saving of best models based on validation loss
- **Early Stopping**: Configurable patience to prevent overfitting
- **Multi-GPU**: Automatic distributed training with Lightning + torchrun

## ğŸ” Data Structure

Expected directory structure for training:

```text
data/
â”œâ”€â”€ volumes/
â”‚   â”œâ”€â”€ subject_001/
â”‚   â”‚   â””â”€â”€ study_volume/
â”‚   â”‚       â””â”€â”€ volume.nii.gz
â”‚   â””â”€â”€ subject_002/
â”‚       â””â”€â”€ study_volume/
â”‚           â””â”€â”€ volume.nii.gz
â””â”€â”€ annotations/
    â”œâ”€â”€ Segmentations.subject_001.ART.nii.gz
    â”œâ”€â”€ Segmentations.subject_001.RA.nii.gz
    â”œâ”€â”€ Segmentations.subject_002.ART.nii.gz
    â””â”€â”€ Segmentations.subject_002.RA.nii.gz
```

Annotation types: `ART` (artery), `RA` (rectus abdominis), `S_FAT` (subcutaneous fat)
