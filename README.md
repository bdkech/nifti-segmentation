# NIFTI Model - Medical Volume Segmentation Pipeline

A comprehensive pipeline for 3D medical volume segmentation using UNetR architecture with Hounsfield Unit support.

## ğŸ“ Project Structure

```
nifti_model/
â”œâ”€â”€ __init__.py                 # Main package with core imports
â”œâ”€â”€ cli/                        # Command Line Interface
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                 # Click-based CLI commands
â”œâ”€â”€ data/                       # Data Loading & Preprocessing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py              # NIFTI dataset and data modules
â”‚   â””â”€â”€ transforms.py           # HU normalization & preprocessing
â”œâ”€â”€ models/                     # Model Architecture & Inference
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ unetr.py                # UNetR Lightning module
â”‚   â””â”€â”€ inference.py            # Volume prediction pipeline
â”œâ”€â”€ training/                   # Training & Experiment Tracking
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py              # Lightning training manager
â”‚   â””â”€â”€ logging.py              # Weights & Biases integration
â””â”€â”€ utils/                      # Configuration & Utilities
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ config.py               # Pydantic configuration classes
    â””â”€â”€ logging.py              # Loguru logging setup
```

## ğŸš€ Usage

### Import Core Components
```python
from nifti_model import (
    NiftiVolumeDataset, NiftiDataModule,
    UNetRModel, VolumePredictor, 
    TrainingManager, Config
)
```

### Import Specific Submodules
```python
# Data processing
from nifti_model.data import (
    HounsfieldUnitNormalizationd,
    create_preprocessing_pipeline
)

# Model components  
from nifti_model.models import UNetRModel, create_predictor

# Training utilities
from nifti_model.training import TrainingManager, setup_wandb

# Configuration
from nifti_model.utils import Config, DataConfig, ModelConfig
```

### CLI Commands
```bash
# Preprocess NIFTI volumes
nifti-model preprocess -d ./data -o ./processed

# Train UNetR model
nifti-model train -d ./processed -o ./models --epochs 100

# Generate predictions
nifti-model predict -m ./models/best.ckpt -i volume.nii.gz -o prediction.nii.gz

# Evaluate model performance  
nifti-model evaluate -m ./models/best.ckpt -t ./test_data
```

## ğŸ¥ Hounsfield Unit Support

The pipeline includes specialized transforms for medical imaging:

- **`HounsfieldUnitNormalizationd`**: Fixed HU windowing with clinical presets
- **`AdaptiveHUNormalizationd`**: Automatic percentile-based windowing
- **Clinical Presets**: soft_tissue, lung, bone, brain, cardiac, etc.

```python
# Configure HU processing
config = Config(
    data=DataConfig(
        use_adaptive_hu_normalization=True,
        hu_window_preset="soft_tissue",  # or custom range
        hu_min=-160.0,
        hu_max=240.0
    )
)
```

## ğŸ”§ Installation

```bash
# Install dependencies
uv add monai torch lightning click loguru nibabel wandb

# Install in development mode
uv pip install -e .
```

## ğŸ“ Configuration

Use YAML configuration files for reproducible experiments:

```yaml
data:
  data_dir: "./data"
  use_adaptive_hu_normalization: true
  target_size: [224, 224, 64]

model:
  img_size: [224, 224, 64]
  feature_size: 16

training:
  epochs: 100
  batch_size: 1
  learning_rate: 1e-4

wandb:
  enabled: true
  project: "medical-segmentation"
```

## ğŸ¯ Key Features

- âœ… **Modular Design**: Logically organized submodules
- âœ… **Medical Imaging**: Hounsfield Unit preprocessing
- âœ… **UNetR Architecture**: MONAI-based implementation
- âœ… **Lightning Integration**: Professional training workflows
- âœ… **Experiment Tracking**: Weights & Biases support
- âœ… **Volume Processing**: Sliding window inference
- âœ… **CLI Interface**: Docker-style commands
- âœ… **Type Safety**: Full type hints throughout